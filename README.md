# ğŸ•·ï¸ crawl-enhance

**From zero to production-ready web scraper.**

By [@anhhoangdev](https://github.com/anhhoangdev)

---

## ğŸ‘‹ What's good!

So you took the seminar. Cool.

But here's the thing â€” those notebooks were just the warmup. This repo is where the real stuff lives.

You want to be a **pro data collector**? Here's the path:

```
ğŸ“š Notebooks (basics)  â†’  ğŸ—ï¸ BatDongSan Crawler (production)  â†’  ğŸš€ Your own project
```

---

## ğŸ“‚ What's in here

```
crawl-enhance/
â”œâ”€â”€ jupter_version/          # ğŸ“š Teaching materials (start here if new)
â”‚   â”œâ”€â”€ PRE_SEMINAR_GUIDE.md
â”‚   â”œâ”€â”€ 01_static_html_scraping.ipynb
â”‚   â”œâ”€â”€ 02_dynamic_content_scraping.ipynb
â”‚   â””â”€â”€ 03_api_based_scraping.ipynb
â”‚
â”œâ”€â”€ batdongsan_crawler/      # ğŸ—ï¸ Production-ready crawler (study this)
â”‚   â””â”€â”€ src/batdongsan/
â”‚       â”œâ”€â”€ domain/          # Entities & business logic
â”‚       â”œâ”€â”€ application/     # Use cases & orchestration
â”‚       â”œâ”€â”€ infrastructure/  # HTTP, parsers, storage
â”‚       â””â”€â”€ interface/       # CLI
â”‚
â””â”€â”€ teaching-examples/       # ğŸ“ Raw Python examples
```

---

## ğŸ“ The Learning Path

### Level 1: Beginner
**Go through the notebooks first.**

| Notebook | What you'll learn |
|----------|-------------------|
| [Module 1](jupter_version/01_static_html_scraping.ipynb) | `requests` + BeautifulSoup |
| [Module 2](jupter_version/02_dynamic_content_scraping.ipynb) | Selenium for JS-heavy sites |
| [Module 3](jupter_version/03_api_based_scraping.ipynb) | Async API scraping (the pro move) |

### Level 2: Intermediate
**Study the production crawler.**

The `batdongsan_crawler/` is a real-world example using:
- âœ… **Clean Architecture** â€” separated concerns, testable code
- âœ… **Cloudflare bypass** â€” using `curl_cffi`
- âœ… **Pydantic validation** â€” every record is typed and validated
- âœ… **Multi-format export** â€” JSON, CSV, JSONL
- âœ… **CLI interface** â€” proper command-line tool

```bash
# Try it yourself
cd batdongsan_crawler
pip install -e .
python -m batdongsan crawl --pages 5
```

### Level 3: Pro
**Build your own.**

Take what you learned and build a crawler for:
- Your favorite e-commerce site
- Job listings
- News aggregator
- Social media data

---

## ğŸ—ï¸ Clean Architecture Crash Course

The production crawler follows Clean Architecture. Here's why it matters:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INTERFACE                     â”‚
â”‚            (CLI, API, whatever)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  APPLICATION                    â”‚
â”‚           (SpiderService, use cases)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    DOMAIN                       â”‚
â”‚     (Entities: PropertyListing, Location)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                INFRASTRUCTURE                   â”‚
â”‚    (HTTP clients, parsers, storage, config)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The rule**: Inner layers don't know about outer layers.

**Why care?**
- Easy to test (mock the infrastructure)
- Easy to swap components (new parser? just implement the interface)
- Easy to understand (each layer has one job)

---

## ğŸ› ï¸ Key Patterns You'll See

| Pattern | Where | Why |
|---------|-------|-----|
| **Dependency Injection** | `container.py` | Swap implementations without changing code |
| **Repository Pattern** | Storage classes | Abstract away data persistence |
| **Strategy Pattern** | Parsers | Different parsing logic, same interface |
| **Rate Limiting** | HTTP client | Don't get banned |

---

## ğŸ“Š Speed Comparison

From Module 3, remember this:

| Method | 200 records | Notes |
|--------|-------------|-------|
| Selenium | ~60s | Browser overhead, JS rendering |
| requests + BS4 | ~10s | Good for static HTML |
| Async API | ~5s | 10x faster, the pro way |

---

## âš ï¸ Ethics & Best Practices

Real talk:
- âœ… Respect `robots.txt`
- âœ… Rate limit (don't DDoS)
- âœ… Check Terms of Service
- âœ… Cache aggressively
- âŒ Don't scrape personal data without consent
- âŒ Don't bypass authentication

---

## ğŸš€ Quick Start

### For students (notebooks)
```bash
# Just open in Colab, no setup needed
```

### For developers (production crawler)
```bash
git clone https://github.com/anhhoangdev/crawl-enhance.git
cd crawl-enhance/batdongsan_crawler
pip install -e .
python -m batdongsan crawl --pages 3
```

---

## ğŸ“š Resources

| Topic | Link |
|-------|------|
| BeautifulSoup | [docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) |
| Selenium Python | [docs](https://selenium-python.readthedocs.io/) |
| aiohttp | [docs](https://docs.aiohttp.org/) |
| Pydantic | [docs](https://docs.pydantic.dev/) |
| curl_cffi | [GitHub](https://github.com/yifeikong/curl_cffi) |
| Clean Architecture | [The Clean Architecture (Uncle Bob)](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html) |

---

## ğŸ¤ Contributing

Found a bug? Want to add a new example?  
PRs welcome.

---

*Go build something cool.* âœŒï¸

â€” [@anhhoangdev](https://github.com/anhhoangdev)
