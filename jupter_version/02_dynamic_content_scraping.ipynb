{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“š Module 2: Dynamic Content Scraping with Selenium\n",
                "\n",
                "**Learn to scrape JavaScript-rendered websites**\n",
                "\n",
                "In this notebook, you'll learn:\n",
                "- Launch a browser with Selenium\n",
                "- Wait for dynamic elements\n",
                "- Extract data from tables\n",
                "- Export to JSON/CSV\n",
                "\n",
                "**Target Website**: [CafeF VNINDEX](https://cafef.vn/du-lieu/Lich-su-giao-dich-vnindex-1.chn) (Stock market data)\n",
                "\n",
                "âš ï¸ **Note for Colab**: Colab runs in headless mode, so you won't see the browser."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”§ Setup\n",
                "Install required packages (run once)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Chrome and Selenium in Colab\n",
                "!apt-get update\n",
                "!apt-get install -y chromium-chromedriver\n",
                "!pip install selenium pydantic pandas -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from selenium import webdriver\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.support.ui import WebDriverWait\n",
                "from selenium.webdriver.support import expected_conditions as EC\n",
                "from selenium.webdriver.chrome.options import Options\n",
                "import time\n",
                "\n",
                "def get_chrome_driver():\n",
                "    \"\"\"Get Chrome driver configured for Colab (headless)\"\"\"\n",
                "    options = Options()\n",
                "    options.add_argument('--headless')  # Run without GUI\n",
                "    options.add_argument('--no-sandbox')\n",
                "    options.add_argument('--disable-dev-shm-usage')\n",
                "    options.add_argument('--disable-gpu')\n",
                "    \n",
                "    driver = webdriver.Chrome(options=options)\n",
                "    return driver\n",
                "\n",
                "print(\"âœ… Driver function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 1: Open a Browser with Selenium\n",
                "\n",
                "**Goal**: Launch Chrome browser and navigate to CafeF\n",
                "\n",
                "**Concepts**:\n",
                "- Selenium WebDriver\n",
                "- Browser automation basics\n",
                "- Headless mode for Colab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\"SELENIUM BROWSER AUTOMATION\")\n",
                "print(\"=\" * 70)\n",
                "print()\n",
                "\n",
                "# Setup Chrome driver\n",
                "print(\"Setting up Chrome driver...\")\n",
                "driver = get_chrome_driver()\n",
                "\n",
                "print(\"âœ… Browser launched successfully!\\n\")\n",
                "\n",
                "# Navigate to CafeF VNINDEX page\n",
                "url = \"https://cafef.vn/du-lieu/Lich-su-giao-dich-vnindex-1.chn\"\n",
                "print(f\"Navigating to: {url}\")\n",
                "driver.get(url)\n",
                "\n",
                "print(\"âœ… Page loaded!\")\n",
                "print(f\"Page title: {driver.title}\")\n",
                "\n",
                "# Clean up\n",
                "driver.quit()\n",
                "print(\"\\nâœ… Browser closed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Key Takeaways\n",
                "\n",
                "- `webdriver.Chrome()` launches Chrome\n",
                "- `driver.get(url)` navigates to a page\n",
                "- `driver.quit()` closes the browser"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 2: Wait for Dynamic Elements\n",
                "\n",
                "**Goal**: Wait for the data table to load before accessing it\n",
                "\n",
                "**Concepts**:\n",
                "- Explicit waits (WebDriverWait)\n",
                "- Expected conditions\n",
                "- Why waiting is important for dynamic content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\"WAITING FOR DYNAMIC CONTENT\")\n",
                "print(\"=\" * 70)\n",
                "print()\n",
                "\n",
                "# Setup driver\n",
                "driver = get_chrome_driver()\n",
                "\n",
                "try:\n",
                "    # Navigate\n",
                "    url = \"https://cafef.vn/du-lieu/Lich-su-giao-dich-vnindex-1.chn\"\n",
                "    print(f\"Loading: {url}\\n\")\n",
                "    driver.get(url)\n",
                "    \n",
                "    # Create a wait object (waits up to 20 seconds)\n",
                "    wait = WebDriverWait(driver, 20)\n",
                "    \n",
                "    print(\"Waiting for table to load...\")\n",
                "    print(\"(This might take a few seconds)\\n\")\n",
                "    \n",
                "    # Wait for the specific table container using XPath\n",
                "    table_xpath = '//*[@id=\"render-table-owner\"]'\n",
                "    \n",
                "    # Wait until the element is present in the DOM\n",
                "    table_element = wait.until(\n",
                "        EC.presence_of_element_located((By.XPATH, table_xpath))\n",
                "    )\n",
                "    \n",
                "    print(\"âœ… Table found!\")\n",
                "    print(f\"Element tag: {table_element.tag_name}\")\n",
                "    \n",
                "    # Give it a bit more time for data to fully render\n",
                "    time.sleep(2)\n",
                "    \n",
                "    # Find all rows in the table\n",
                "    rows = table_element.find_elements(By.TAG_NAME, \"tr\")\n",
                "    print(f\"âœ… Found {len(rows)} rows in the table\\n\")\n",
                "    \n",
                "    # Print first row as example\n",
                "    if rows:\n",
                "        print(\"=\" * 70)\n",
                "        print(\"FIRST ROW PREVIEW:\")\n",
                "        print(\"=\" * 70)\n",
                "        first_row = rows[0]\n",
                "        cells = first_row.find_elements(By.TAG_NAME, \"td\")\n",
                "        print(f\"Number of columns: {len(cells)}\")\n",
                "        if cells:\n",
                "            print(f\"First column: {cells[0].text}\")\n",
                "            if len(cells) > 1:\n",
                "                print(f\"Second column: {cells[1].text}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"âŒ Error: {e}\")\n",
                "    \n",
                "finally:\n",
                "    driver.quit()\n",
                "    print(\"\\nâœ… Browser closed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Key Takeaways\n",
                "\n",
                "- `WebDriverWait(driver, timeout)` creates a wait object\n",
                "- `EC.presence_of_element_located()` waits for element to exist\n",
                "- Dynamic content needs time to load!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 3: Extract Table Data\n",
                "\n",
                "**Goal**: Extract stock data from the table\n",
                "\n",
                "**Concepts**:\n",
                "- XPath selectors\n",
                "- Table row/cell navigation\n",
                "- Basic data cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\"EXTRACTING TABLE DATA WITH XPATH\")\n",
                "print(\"=\" * 70)\n",
                "print()\n",
                "\n",
                "# Setup\n",
                "driver = get_chrome_driver()\n",
                "\n",
                "try:\n",
                "    # Navigate and wait\n",
                "    url = \"https://cafef.vn/du-lieu/Lich-su-giao-dich-vnindex-1.chn\"\n",
                "    driver.get(url)\n",
                "    \n",
                "    wait = WebDriverWait(driver, 20)\n",
                "    table_xpath = '//*[@id=\"render-table-owner\"]'\n",
                "    \n",
                "    print(\"Waiting for table...\")\n",
                "    table = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath)))\n",
                "    time.sleep(2)\n",
                "    \n",
                "    # Find all rows\n",
                "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
                "    print(f\"Found {len(rows)} rows\\n\")\n",
                "    \n",
                "    print(\"=\" * 70)\n",
                "    print(\"EXTRACTED DATA (First 5 rows):\")\n",
                "    print(\"=\" * 70)\n",
                "    \n",
                "    # Extract data from each row\n",
                "    for i, row in enumerate(rows[:5], 1):  # First 5 rows only\n",
                "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
                "        \n",
                "        if not cells:\n",
                "            continue\n",
                "        \n",
                "        # Extract text from each cell\n",
                "        cell_data = [cell.text.strip() for cell in cells]\n",
                "        \n",
                "        # CafeF table structure:\n",
                "        # 0: Date, 1: Close, 9: Open, 10: High, 11: Low\n",
                "        \n",
                "        print(f\"\\n--- Row {i} ---\")\n",
                "        if len(cell_data) > 0:\n",
                "            print(f\"Date:        {cell_data[0]}\")\n",
                "        if len(cell_data) > 1:\n",
                "            print(f\"Close Price: {cell_data[1]}\")\n",
                "        if len(cell_data) > 9:\n",
                "            print(f\"Open Price:  {cell_data[9]}\")\n",
                "        if len(cell_data) > 10:\n",
                "            print(f\"High Price:  {cell_data[10]}\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(\"âœ… Successfully extracted data from table!\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"âŒ Error: {e}\")\n",
                "    \n",
                "finally:\n",
                "    driver.quit()\n",
                "    print(\"\\nâœ… Browser closed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 4: Complete Crawler with Export\n",
                "\n",
                "**Goal**: Full crawler with Pydantic validation and CSV/JSON export\n",
                "\n",
                "**Concepts**:\n",
                "- Complete scraping workflow\n",
                "- Pydantic data validation\n",
                "- Multiple export formats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydantic import BaseModel, Field\n",
                "import json\n",
                "import pandas as pd\n",
                "\n",
                "# Define Pydantic model\n",
                "class StockData(BaseModel):\n",
                "    \"\"\"Represents VNINDEX trading data for a single day\"\"\"\n",
                "    date: str = Field(..., description=\"Trading date\")\n",
                "    open_price: float = Field(default=0.0, description=\"Opening price\")\n",
                "    close_price: float = Field(default=0.0, description=\"Closing price\")\n",
                "    high_price: float = Field(default=0.0, description=\"Highest price\")\n",
                "    low_price: float = Field(default=0.0, description=\"Lowest price\")\n",
                "\n",
                "def parse_float(text):\n",
                "    \"\"\"Convert text to float, handling various formats\"\"\"\n",
                "    if not text or text == '-':\n",
                "        return 0.0\n",
                "    try:\n",
                "        return float(text.replace(',', ''))\n",
                "    except ValueError:\n",
                "        return 0.0\n",
                "\n",
                "print(\"âœ… Models defined!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def scrape_vnindex():\n",
                "    \"\"\"Scrape VNINDEX trading data from CafeF\"\"\"\n",
                "    print(\"=\" * 70)\n",
                "    print(\"COMPLETE VNINDEX CRAWLER\")\n",
                "    print(\"=\" * 70)\n",
                "    print()\n",
                "    \n",
                "    driver = get_chrome_driver()\n",
                "    results = []\n",
                "    \n",
                "    try:\n",
                "        url = \"https://cafef.vn/du-lieu/Lich-su-giao-dich-vnindex-1.chn\"\n",
                "        print(f\"Loading: {url}\")\n",
                "        driver.get(url)\n",
                "        \n",
                "        wait = WebDriverWait(driver, 20)\n",
                "        table_xpath = '//*[@id=\"render-table-owner\"]'\n",
                "        print(\"Waiting for data table...\")\n",
                "        \n",
                "        table = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath)))\n",
                "        time.sleep(2)\n",
                "        \n",
                "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
                "        print(f\"Found {len(rows)} rows\")\n",
                "        print(\"Extracting data...\\n\")\n",
                "        \n",
                "        for row in rows:\n",
                "            try:\n",
                "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
                "                if not cells:\n",
                "                    continue\n",
                "                \n",
                "                cell_texts = [c.text.strip() for c in cells]\n",
                "                \n",
                "                date = cell_texts[0] if len(cell_texts) > 0 else \"\"\n",
                "                if not date or \"NgÃ y\" in date:\n",
                "                    continue\n",
                "                \n",
                "                stock_data = StockData(\n",
                "                    date=cell_texts[0] if len(cell_texts) > 0 else \"\",\n",
                "                    open_price=parse_float(cell_texts[9] if len(cell_texts) > 9 else \"0\"),\n",
                "                    close_price=parse_float(cell_texts[1] if len(cell_texts) > 1 else \"0\"),\n",
                "                    high_price=parse_float(cell_texts[10] if len(cell_texts) > 10 else \"0\"),\n",
                "                    low_price=parse_float(cell_texts[11] if len(cell_texts) > 11 else \"0\")\n",
                "                )\n",
                "                \n",
                "                results.append(stock_data)\n",
                "                \n",
                "            except Exception as e:\n",
                "                continue\n",
                "        \n",
                "        print(f\"âœ… Successfully extracted {len(results)} trading days\\n\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"âŒ Error during scraping: {e}\")\n",
                "        \n",
                "    finally:\n",
                "        driver.quit()\n",
                "        print(\"Browser closed\\n\")\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the crawler\n",
                "data = scrape_vnindex()\n",
                "\n",
                "if data:\n",
                "    # Convert to DataFrame\n",
                "    df = pd.DataFrame([d.model_dump() for d in data])\n",
                "    \n",
                "    # Save to CSV\n",
                "    csv_file = \"vnindex_data.csv\"\n",
                "    df.to_csv(csv_file, index=False)\n",
                "    print(f\"ðŸ’¾ Saved to: {csv_file}\")\n",
                "    \n",
                "    # Save to JSON\n",
                "    json_file = \"vnindex_data.json\"\n",
                "    with open(json_file, \"w\", encoding=\"utf-8\") as f:\n",
                "        json.dump([d.model_dump() for d in data], f, indent=2)\n",
                "    print(f\"ðŸ’¾ Saved to: {json_file}\")\n",
                "    \n",
                "    # Print sample\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(\"SAMPLE DATA:\")\n",
                "    print(\"=\" * 70)\n",
                "    print(df.head())\n",
                "    \n",
                "    print(\"\\nðŸŽ‰ Complete! You've built a Selenium web scraper!\")\n",
                "else:\n",
                "    print(\"âŒ No data extracted!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ† Exercises\n",
                "\n",
                "1. **Add more fields**: Extract volume, change percentage\n",
                "2. **Pagination**: Click \"Next\" button to get more data\n",
                "3. **Different index**: Modify for HNX instead of VNINDEX\n",
                "4. **Data analysis**: Plot the closing prices using matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise: Plot the data\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "if 'df' in dir() and len(df) > 0:\n",
                "    plt.figure(figsize=(12, 5))\n",
                "    plt.plot(df['close_price'].head(20), marker='o')\n",
                "    plt.title('VNINDEX Close Price (Last 20 days)')\n",
                "    plt.xlabel('Day')\n",
                "    plt.ylabel('Price')\n",
                "    plt.grid(True)\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
